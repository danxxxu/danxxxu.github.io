<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Sound of Standing</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
      rel="stylesheet"
    />
    <link
    id="favicon"
    rel="icon"
    href="https://cdn.glitch.global/9f185785-b86c-49bc-814e-3f21ca824fbd/favicon.ico?v=1655276293402"
    type="image/x-icon"
  />
  <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <div class="head">
      <div id="profile">
        <img style="border-radius: 50%; width: 60px; height: 60px; object-fit: cover; float: left; margin-right: 20px;" src="resources/profile.jpg" alt="a chinese woman with short hair wearing a virtual reality headset looking at her hands through the sensors" />
        <div id="name">Dan Xu</div>
      </div>
      <div id="nav">
        &nbsp;<span><a href="/about.html">About</a></span>&nbsp;&nbsp;&nbsp;<span><a href="/index.html">Projects</a></span>
      </div>
    </div>
    <div class="content">
      <div class="title">Sound of Standing (2017)</div>
      <p><i>Deep Meaning</i> is an experiment in Sensory Augmentation and Movement Sonification that translates body sway movement during standing, of which we are usually unaware, into sound. It is largely inspired by the early sensory substitution experiments by <a href="https://en.wikipedia.org/wiki/Paul_Bach-y-Rita" target="_blank">Paul Bach-y-Rita</a>.</p>
      <div class="img_project">
        <img src="resources/projects/standing/photo 4.JPG" alt="a woman wearing a headphone standing on a piece of foam blindfolded" />
      </div>
      <p>In this research, I translate the body sway movement of standing, of which we are usually unaware, into sound. The sway movement is captured with an accelerometer and mapping into various parameters controlling a vowel-formant synthesiser as a sonification method. A series of experiment are conducted to evaluate the effectiveness of different mapping strategies.</p>
      <div class="img_project">
        <img src="resources/projects/standing/sway.jpg" alt="an image demonstrating the slight sway movement while standing" />
      </div>
      <div class="img_project">
        <img src="resources/projects/standing/system layout.jpg" alt="explain the system layout of the movement sonification system with data captured by an accelerometer attached to the participant's lower back and send to a laptop and generates sound via headphone" />
      </div>
      <div class="img_project">
        <img src="resources/projects/standing/movement sonification.jpg" alt="explain movement sonififaction translating movement related data into sound synthesis parameters" />
      </div>
      <p>Here some of the sounds here:</p>
      <div class="iframewrapper">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/z4enw0xsRYw?si=lLVLNuNQRtieOrl9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      </div>
      <div class="img_project">
        <img src="resources/projects/standing/exp1.jpg" alt="experiment 1 focuses on pitch change in frontal plane" />
      </div>
      <div class="img_project">
        <img src="resources/projects/standing/exp2.jpg" alt="experiment 2 focuses on pitch change continuously or in steps" />
      </div>
      <div class="img_project">
        <img src="resources/projects/standing/exp3.jpg" alt="experiment 3 focuses on left-right panning or binaural" />
      </div>
      <div class="img_project">
        <img src="resources/projects/standing/exp3.jpg" alt="experiment 4 focuses on pitch on the left and right plane" />
      </div>
      <p> The audio feedback system showed positive effects on postural control. Most subjects preferred pitch decrease as they swayed forward, because it simulates an natural scream as they fall forward. The continuous scaling function was reported as more responsive despite that there was no reported perceptual difference between the two scaling functions tested in experiment 2. The panning technique was adopted after experiment 3 because more subjects found it easier to control comparing with binaural technique. Also, the non-individualised Head Related Transform Function (HRTF) may resulted in perceptual differences among individuals. Lastly, more subjects thought that the choice of associating pitch change with front/back sway and timbre change with left/right sway was more informative than timbre change with front/back sway and pitch change with left/right sway.</p>
      <p><i>Sound of Standing</i> is part of my master graduation project for Media Technology program at Leiden University. <a href="https://theses.liacs.nl/pdf/2016-2017-XuD.pdf" target="_blank">Read the full thesis here</a>. </p>
  </div>
    <div class="credit">&#169; Dan Xu 2025. All rights reserved.</div>
  </body>
</html>
